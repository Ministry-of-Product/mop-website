---
layout: default
title: About
description: A perspective on why judgment matters when scaling businesses with AI-enabled systems.
permalink: /about/
meta_description: A perspective on why judgment matters when scaling with AI. The biggest risk is bad sequencing, not technical failure. Learn how I think about these problems.
---

# About

This isn't a résumé. It's a perspective statement.

## Why Judgment Matters

The biggest risk when scaling with AI isn't technical failure. It's bad sequencing.

Most businesses waste months building AI systems that don't compound. They scale noise instead of judgment. They commit to experiments as if they were permanent infrastructure. They build the wrong thing first.

I've spent years working across product, data, and systems. The pattern I see repeatedly: businesses get stuck not because they lack capability, but because they lack clarity about what decision actually matters right now.

## How I Think

- **Clarity beats speed** — Better to move slowly in the right direction than quickly in the wrong one
- **Experiments over commitments** — Early systems should be treated as experiments, not permanent infrastructure
- **Restraint over volume** — Saying no is often the highest-leverage move
- **Judgment over tools** — AI should scale judgment and strategy, not noise

## What I Bring

Experience across product management, data systems, and building things that need to work in the real world. A bias toward plainspoken analysis over hype. Focus on decisions and sequencing, not tools and tactics.

If you have revenue, clients, and authority—and you're trying to scale with AI—[let's talk](/advisory).

